{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4e7471",
   "metadata": {},
   "source": [
    "# Bias Response Curve Experiment\n",
    "\n",
    "This notebook measures how adding a gender steering vector to GPT-2 Small’s hidden state changes its output.\n",
    "\n",
    "- Loads GPT-2 Small via TransformerLens\n",
    "- Computes a gender bias steering vector (\" he\" vs \" she\") at a chosen layer/hook site\n",
    "- Sweeps α and injects at inference; reports logit differences Δ = logit(\" he\") − logit(\" she\")\n",
    "- Compares to random and orthogonal directions (controls)\n",
    "- Uses consistent BOS/tokenization and auto-detects decision position t\\*\n",
    "- Saves plot and prints basic stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinism env (set before Torch ops for cuBLAS determinism)\n",
    "import os\n",
    "\n",
    "os.environ.setdefault(\"CUBLAS_WORKSPACE_CONFIG\", \":4096:8\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# Repro + determinism\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "try:\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "except Exception:\n",
    "    pass\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\").to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29b808b",
   "metadata": {},
   "source": [
    "## Define Prompts and READ/WRITE Layer\n",
    "\n",
    "- Shared prefix with trailing space; compute t\\* from tokens (with BOS)\n",
    "- Target IDs from leading-space forms\n",
    "- Inject at `blocks.{INJECT_LAYER}.hook_resid_mid`; read final `blocks.{L-1}.hook_resid_post`\n",
    "- Narrow alpha sweep near linear regime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPEND_BOS = True\n",
    "prefix = \"The doctor said that \"\n",
    "\n",
    "toks_prefix = model.to_tokens(prefix, prepend_bos=PREPEND_BOS).to(device)\n",
    "T_STAR = toks_prefix.shape[1] - 1  # last token index for this input\n",
    "\n",
    "he_id = int(model.to_tokens(\" he\", prepend_bos=False)[0, 0])\n",
    "she_id = int(model.to_tokens(\" she\", prepend_bos=False)[0, 0])\n",
    "\n",
    "INJECT_LAYER = 3\n",
    "READ_LAYER = model.cfg.n_layers - 1\n",
    "INJECT_HOOK_NAME = f\"blocks.{INJECT_LAYER}.hook_resid_mid\"\n",
    "READ_HOOK_NAME = f\"blocks.{READ_LAYER}.hook_resid_post\"\n",
    "\n",
    "alphas = np.array([-0.5, -0.25, -0.125, -0.0625, 0, 0.0625, 0.125, 0.25, 0.5], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78de11f",
   "metadata": {},
   "source": [
    "### Clean logit lens sanity check (final input token t\\*)\n",
    "\n",
    "- Clean logit lens = take the hidden state, apply the model’s final LayerNorm, then unembed to get next-token logits.\n",
    "- t\\* = last token of the input (position where next-token logits are predicted).\n",
    "- From cache at read site: apply ln_final → unembed → get clean-lens logits.\n",
    "- Compare with model’s true head logits at t\\*.\n",
    "- Pass if max(|lens − real|) < 1e-5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e637bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def lens_logits_at_tstar(tokens, read_hook_name=READ_HOOK_NAME, apply_ln_final=True):\n",
    "    cache = {}\n",
    "\n",
    "    def read_hook(act, hook):\n",
    "        cache[\"resid\"] = act.detach().clone()\n",
    "        return act\n",
    "\n",
    "    _ = model.run_with_hooks(tokens, return_type=None, stop_at_layer=READ_LAYER + 1, fwd_hooks=[(read_hook_name, read_hook)])\n",
    "    local_tstar = tokens.shape[1] - 1\n",
    "    resid = cache[\"resid\"][:, local_tstar : local_tstar + 1, :]\n",
    "    if apply_ln_final:\n",
    "        resid = model.ln_final(resid)\n",
    "    return model.unembed(resid)[0, 0, :]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def head_logits_at_tstar(tokens):\n",
    "    local_tstar = tokens.shape[1] - 1\n",
    "    return model(tokens, return_type=\"logits\")[0, local_tstar, :]\n",
    "\n",
    "\n",
    "# Compute logits at t* using both the clean lens and the model's head\n",
    "logits_lens = lens_logits_at_tstar(toks_prefix)\n",
    "logits_head = head_logits_at_tstar(toks_prefix)\n",
    "\n",
    "# Compute the maximum absolute difference between the two methods\n",
    "max_abs_diff = (logits_lens - logits_head).abs().max().item()\n",
    "print({\"lens_vs_head_max_abs_diff\": max_abs_diff})\n",
    "\n",
    "# Sanity check: the two methods should agree to high precision\n",
    "assert max_abs_diff < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a0068f",
   "metadata": {},
   "source": [
    "## Get Activations for \"He\" and \"She\" at the Chosen Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25817e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_LIST = [\n",
    "    \"The doctor said that \",\n",
    "    \"The nurse mentioned that \",\n",
    "    \"The engineer argued that \",\n",
    "    \"The teacher noted that \",\n",
    "    \"The manager reported that \",\n",
    "    \"The journalist said that \",\n",
    "    \"The lawyer stated that \",\n",
    "    \"The chef remarked that \",\n",
    "    \"The professor explained that \",\n",
    "    \"The scientist observed that \",\n",
    "]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def residual_first_cont_token(prefix_text, continuation, layer, site=\"hook_resid_mid\"):\n",
    "    \"\"\"\n",
    "    Return residual at the FIRST token of the continuation (i.e., pronoun),\n",
    "    at the given layer/site.\n",
    "    \"\"\"\n",
    "    toks_prefix_only = model.to_tokens(prefix_text, prepend_bos=True).to(device)\n",
    "    pos_cont0 = toks_prefix_only.shape[1]  # index of first continuation token (t* + 1)\n",
    "\n",
    "    toks = model.to_tokens(prefix_text + continuation, prepend_bos=True).to(device)\n",
    "\n",
    "    cache = {}\n",
    "\n",
    "    def grab(activation, hook):\n",
    "        cache[\"resid\"] = activation.detach()\n",
    "        return activation\n",
    "\n",
    "    _ = model.run_with_hooks(toks, return_type=None, stop_at_layer=layer + 1, fwd_hooks=[(f\"blocks.{layer}.{site}\", grab)])\n",
    "\n",
    "    return cache[\"resid\"][0, pos_cont0, :].clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3e129",
   "metadata": {},
   "source": [
    "## Compute Bias and Orthogonal Vectors\n",
    "\n",
    "- Contrastive: average `h_t*(he) - h_t*(she)` across prefixes\n",
    "- Gradient fallback: local decision-aligned direction\n",
    "- Controls: random same-norm; orth via Gram–Schmidt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c867b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_v_bias_contrastive(layer=INJECT_LAYER):\n",
    "    v_sum = torch.zeros(model.cfg.d_model, device=device)\n",
    "    for prefix in PREFIX_LIST:\n",
    "        residual_he = residual_first_cont_token(prefix, \" he\", layer)\n",
    "        residual_she = residual_first_cont_token(prefix, \" she\", layer)\n",
    "        v_sum += residual_he - residual_she\n",
    "    v_bias = v_sum / (v_sum.norm() + 1e-8)\n",
    "    return v_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8116c",
   "metadata": {},
   "source": [
    "### Build Bias Vectors\n",
    "\n",
    "- Main bias vector using contrastive method (he vs she differences)\n",
    "- Random and orthogonal control vectors for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) normalize v_bias\n",
    "v_bias_raw = build_v_bias_contrastive(INJECT_LAYER)\n",
    "nb = v_bias_raw.norm()\n",
    "v_bias = v_bias_raw / nb  # unit length\n",
    "\n",
    "# 2) orient v_bias so +alpha favors \" he\"\n",
    "eps = 1e-3\n",
    "d_plus = delta_lens_at_tstar(+eps, v_bias)\n",
    "d_minus = delta_lens_at_tstar(-eps, v_bias)\n",
    "\n",
    "if d_plus < d_minus:  # slope is negative → flip\n",
    "    v_bias = -v_bias\n",
    "\n",
    "# 3) controls with same norm\n",
    "v_rand = torch.randn_like(v_bias)\n",
    "v_rand /= v_rand.norm() + 1e-8\n",
    "v_orth = v_rand - (v_rand @ v_bias) * v_bias\n",
    "v_orth /= v_orth.norm() + 1e-8\n",
    "# (unit norm → alpha is comparable across bias/random/orth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1011fc",
   "metadata": {},
   "source": [
    "## Measurement function (single step at t\\*)\n",
    "\n",
    "- Inject at t* only; cache read-site at t*; `ln_final` then `unembed`\n",
    "- Assert Δ(α=0) equals unmodified clean-lens Δ at t\\*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def delta_lens_at_tstar(alpha, vector, prefix_text=prefix, inject_hook_name=INJECT_HOOK_NAME, read_hook_name=READ_HOOK_NAME):\n",
    "    # Compute local t* for this prefix\n",
    "    toks = model.to_tokens(prefix_text, prepend_bos=True).to(device)\n",
    "    local_tstar = toks.shape[1] - 1\n",
    "    cache = {}\n",
    "\n",
    "    def steer(act, hook):\n",
    "        act[:, local_tstar, :] = act[:, local_tstar, :] + alpha * vector\n",
    "        return act\n",
    "\n",
    "    def readh(act, hook):\n",
    "        cache[\"resid\"] = act.detach().clone()\n",
    "        return act\n",
    "\n",
    "    _ = model.run_with_hooks(toks, return_type=None, stop_at_layer=max(INJECT_LAYER, READ_LAYER) + 1, fwd_hooks=[(inject_hook_name, steer), (read_hook_name, readh)])\n",
    "    resid = model.ln_final(cache[\"resid\"][:, local_tstar : local_tstar + 1, :])\n",
    "    logits = model.unembed(resid)[0, 0, :]\n",
    "    return float((logits[he_id] - logits[she_id]).item())\n",
    "\n",
    "\n",
    "zero_delta = delta_lens_at_tstar(0.0, v_bias, prefix)\n",
    "unmod_delta = float((lens_logits_at_tstar(toks_prefix)[he_id] - lens_logits_at_tstar(toks_prefix)[she_id]).item())\n",
    "print({\"zero_alpha_delta\": zero_delta, \"unmodified_delta\": unmod_delta})\n",
    "assert abs(zero_delta - unmod_delta) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90379d5",
   "metadata": {},
   "source": [
    "## Sweep Alpha Values and Collect Results\n",
    "\n",
    "- Sweep on main prefix and a neutral control (\"Today \")\n",
    "- Fit slopes over the four smallest |α| points; expect bias ≠ 0, random ≈ 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sweep(vectors, alpha_grid, prefix_text):\n",
    "    out = {k: [] for k in vectors}\n",
    "    for a in alpha_grid:\n",
    "        for name, vec in vectors.items():\n",
    "            out[name].append(delta_lens_at_tstar(float(a), vec, prefix_text))\n",
    "    return out\n",
    "\n",
    "\n",
    "vectors = {\"bias\": v_bias, \"random\": v_rand, \"orth\": v_orth}\n",
    "results_main = run_sweep(vectors, alphas, prefix)\n",
    "results_null = run_sweep(vectors, alphas, \"Today \")\n",
    "\n",
    "print(\"alpha grid:\", alphas)\n",
    "print(\"ranges main:\", {k: (float(np.min(v)), float(np.max(v))) for k, v in results_main.items()})\n",
    "print(\"ranges null:\", {k: (float(np.min(v)), float(np.max(v))) for k, v in results_null.items()})\n",
    "\n",
    "fit_sel = np.argsort(np.abs(alphas))[:4]\n",
    "\n",
    "\n",
    "def slope_near_zero(y):\n",
    "    X = np.vstack([alphas[fit_sel], np.ones_like(fit_sel, float)]).T\n",
    "    beta, _ = np.linalg.lstsq(X, np.array(y)[fit_sel], rcond=None)[0]\n",
    "    return float(beta)\n",
    "\n",
    "\n",
    "slopes = {k: slope_near_zero(v) for k, v in results_main.items()}\n",
    "print(\"near-zero slopes (main):\", {k: round(v, 6) for k, v in slopes.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c341ed",
   "metadata": {},
   "source": [
    "## Plot Results\n",
    "\n",
    "- Title includes inject/read sites and t\\*\n",
    "- Save as `brc_gpt2s_injL{...}_readL{...}_tstar.png`\n",
    "- Print acceptance highlights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e393d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "colors = {\"bias\": \"#0072B2\", \"random\": \"#D55E00\", \"orth\": \"#009E73\"}\n",
    "for name in [\"bias\", \"random\", \"orth\"]:\n",
    "    ax.plot(alphas, results_main[name], label=name, color=colors[name], linewidth=2.5 if name == \"bias\" else 2, marker=\"o\", markersize=3)\n",
    "\n",
    "ax.axhline(0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "ax.set_xlabel(\"alpha\", fontsize=14)\n",
    "ax.set_ylabel(\"Δ_logit = logit(' he') - logit(' she')\", fontsize=14)\n",
    "ax.set_title(f\"BRC (GPT-2 small) | inj L{INJECT_LAYER}:hook_resid_mid → read L{READ_LAYER}:hook_resid_post | t*={T_STAR}\", fontsize=15, weight=\"bold\")\n",
    "ax.legend(frameon=True, fontsize=11)\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "\n",
    "note = f\"clean logit lens (ln_final=on), BOS={PREPEND_BOS}, prefix='{prefix}'\"\n",
    "ax.text(0.01, -0.14, note, transform=ax.transAxes, fontsize=10, color=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_path = f\"brc_gpt2s_injL{INJECT_LAYER}_readL{READ_LAYER}_tstar.png\"\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved:\", fig_path)\n",
    "print(\"lens_vs_head_match:\", max_abs_diff < 1e-5)\n",
    "print(\"slopes near zero:\", {k: round(v, 6) for k, v in slopes.items()})\n",
    "print(\"alpha range:\", alphas.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
